{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "from scipy import ndimage\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = 'original_dataset'\n",
    "\n",
    "\n",
    "def mk_new_dir(parent):\n",
    "    os.mkdir(parent)\n",
    "\n",
    "    for label in os.listdir(f'{dataset_dir}'):\n",
    "        os.mkdir(f'{parent}/{label}')\n",
    "\n",
    "\n",
    "def count_dataset(parent):\n",
    "    for label in os.listdir(parent):\n",
    "        label_dir = f'{parent}/{label}'\n",
    "        print(f'{label}:{len (os.listdir(label_dir)) }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROP AND RESIZE TO 255 X 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize(img):\n",
    "    new_size = img.shape[0] if img.shape[0] < img.shape[1] else img.shape[1]\n",
    "\n",
    "    # ketika citra landscape\n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        starting_w_point = (img.shape[1]-new_size) // 2\n",
    "        new_image = img[:,  starting_w_point:starting_w_point+new_size, :]\n",
    "\n",
    "    # ketika citra potrait\n",
    "    else:\n",
    "        starting_h_point = (img.shape[1]-new_size) // 2\n",
    "        new_image = img[starting_h_point:starting_h_point+new_size, :, :]\n",
    "\n",
    "    new_image = cv2.resize(new_image, (255, 255), interpolation=cv2.INTER_AREA)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION UTILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# data augmentation\n",
    "def data_augmentation(label, multiplier):\n",
    "    print('Processing '+label+' thread started')\n",
    "    data_aug = tf.keras.Sequential([\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"), #metode membalik citra\n",
    "        layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='constant', fill_value=255), #metode rotasi citra \n",
    "        layers.experimental.preprocessing.RandomTranslation(0.1, 0.1, fill_mode='constant', fill_value=255) #metode translasi\n",
    "    ])\n",
    "    # add image to batch\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir('original_dataset/'+label):\n",
    "        img_dir = f'original_dataset/{label}/{filename}'\n",
    "        img_pil = load_img(img_dir)\n",
    "        img = img_to_array(img_pil)\n",
    "        img = img.astype(np.uint8)\n",
    "        # crop and resize\n",
    "        img = crop_resize(img)\n",
    "\n",
    "        images.append(img)\n",
    "        filenames.append(filename)\n",
    "\n",
    "\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "\n",
    "    for i in range(multiplier):\n",
    "        aug_images = data_aug(images)\n",
    "        for j in range(len(aug_images)):\n",
    "            tf.keras.utils.save_img(\n",
    "                'augmented_dataset/'+label+'/'+str(i)+'_' + filenames[j], aug_images[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh_apple:182\n",
      "stale_apple:253\n",
      "fresh_apple:546\n",
      "stale_apple:506\n"
     ]
    }
   ],
   "source": [
    "# CEK JUMLAH DATASET MASING MASING LABEL\n",
    "count_dataset('original_dataset')\n",
    "count_dataset('augmented_dataset')\n",
    "\n",
    "# kita target 500 gambar perlabel\n",
    "target = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisialisasi folder\n",
    "mk_new_dir('augmented_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fresh_apple thread started\n",
      "(182, 255, 255, 3)\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Processing stale_apple thread started\n",
      "(253, 255, 255, 3)\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x0000013F469F48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import _thread as thread\n",
    "for label in os.listdir('original_dataset'):\n",
    "    mult = target//len(os.listdir('original_dataset/'+label)) + 1\n",
    "    try:\n",
    "        data_augmentation(label, mult)\n",
    "    except Exception as e:\n",
    "        print('error at thread ', label)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENTASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat folder untuk segmentasi dataset\n",
    "mk_new_dir('segmented_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dir = 'augmented_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi ini dibuat untuk melakukan segmentasi citra (memisahkan objek dengan backgroundnya) \n",
    "\n",
    "def segmentasi(label):\n",
    "    for filename in os.listdir(f'{augmented_dir}/{label}'):\n",
    "        # read image\n",
    "        img = plt.imread(f'augmented_dataset/{label}/{filename}')\n",
    "\n",
    "        # convert ke grb\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # threshold\n",
    "        img_binary = gray<160\n",
    "\n",
    "        # cari mask\n",
    "        mask = ndimage.binary_fill_holes(img_binary)\n",
    "        mask_int = (mask*1).astype(np.uint8)\n",
    "        mask_erode = cv2.erode(mask_int,\n",
    "                        np.array([[1, 1, 1],\n",
    "                                  [1, 1, 1],\n",
    "                                  [1, 1, 1],\n",
    "                                  ]), 2)\n",
    "\n",
    "        # masking\n",
    "        with_mask = img * np.repeat(mask_erode[...,None], 3, axis=2)\n",
    "        \n",
    "        # croping\n",
    "        cnts = cv2.findContours(mask_erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        x,y,w,h = cv2.boundingRect(cnts[len(cnts)-1])\n",
    "        with_mask_croped = with_mask[ y:y+h,x:x+w, :]\n",
    "\n",
    "        plt.imsave( f'segmented_dataset/{label}/{filename}', with_mask_croped )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for label in os.listdir(dataset_dir):\n",
    "    t = threading.Thread(target=segmentasi, args=(label,))\n",
    "    threads.append(t)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)                      #ubah ke bentuk hsv\n",
    "    hue = hsv[:,:,0]                                                #mengambil nilai hue dari format hsv\n",
    "    hist = np.histogram(hue, bins=np.arange(256), density=True)\n",
    "    return hist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'fresh_apple': 0,\n",
    "    'stale_apple': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EKSTRAKSI WARNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for label in os.listdir('segmented_dataset'):\n",
    "    for filename in os.listdir(f'segmented_dataset/{label}'):\n",
    "        img_path = f'segmented_dataset/{label}/{filename}'\n",
    "        img = plt.imread(img_path)\n",
    "        feature = [filename, *features(img), labels[label]]\n",
    "        all_features.append(feature)\n",
    "\n",
    "# konversi ke numpy object\n",
    "all_features = np.array(all_features)\n",
    "\n",
    "# buat kolom untuk setiap nilai hue dan label di last column\n",
    "column = ['img_ids', * np.arange(255), 'label']\n",
    "\n",
    "# simpan dataframe\n",
    "trains_df = pd.DataFrame(all_features, columns=column)\n",
    "trains_df.to_csv('color_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_ids</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_Screen Shot 2018-06-08 at 4.59.36 PM.png</td>\n",
       "      <td>0.464249</td>\n",
       "      <td>0.065132</td>\n",
       "      <td>0.081295</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>0.062982</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0_Screen Shot 2018-06-08 at 4.59.49 PM.png</td>\n",
       "      <td>0.500212</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>0.042468</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>0.029628</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0_Screen Shot 2018-06-08 at 4.59.57 PM.png</td>\n",
       "      <td>0.789681</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.028958</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0_Screen Shot 2018-06-08 at 5.00.03 PM.png</td>\n",
       "      <td>0.657682</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>0.046521</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0_Screen Shot 2018-06-08 at 5.00.12 PM.png</td>\n",
       "      <td>0.504094</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.042860</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.027059</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     img_ids         0         1  \\\n",
       "0           0  0_Screen Shot 2018-06-08 at 4.59.36 PM.png  0.464249  0.065132   \n",
       "1           1  0_Screen Shot 2018-06-08 at 4.59.49 PM.png  0.500212  0.049599   \n",
       "2           2  0_Screen Shot 2018-06-08 at 4.59.57 PM.png  0.789681  0.029041   \n",
       "3           3  0_Screen Shot 2018-06-08 at 5.00.03 PM.png  0.657682  0.054741   \n",
       "4           4  0_Screen Shot 2018-06-08 at 5.00.12 PM.png  0.504094  0.034468   \n",
       "\n",
       "          2         3         4         5         6         7  ...  246  247  \\\n",
       "0  0.081295  0.077266  0.062982  0.048076  0.034349  0.025591  ...  0.0  0.0   \n",
       "1  0.037056  0.042468  0.043359  0.029628  0.021711  0.022263  ...  0.0  0.0   \n",
       "2  0.028958  0.020588  0.008913  0.003515  0.003264  0.003557  ...  0.0  0.0   \n",
       "3  0.046521  0.063355  0.061896  0.012435  0.009378  0.008336  ...  0.0  0.0   \n",
       "4  0.042860  0.044064  0.058678  0.057220  0.027059  0.018378  ...  0.0  0.0   \n",
       "\n",
       "   248  249  250  251  252  253       254  label  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000      0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.000021      0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.000000      0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.000000      0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.000000      0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('color_dataset.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fresh_apple', 'stale_apple']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\n",
    "    'segmented_dataset'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464249</td>\n",
       "      <td>0.065132</td>\n",
       "      <td>0.081295</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>0.062982</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500212</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>0.042468</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>0.029628</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789681</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.028958</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657682</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>0.046521</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504094</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.042860</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.027059</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.464249  0.065132  0.081295  0.077266  0.062982  0.048076  0.034349   \n",
       "1  0.500212  0.049599  0.037056  0.042468  0.043359  0.029628  0.021711   \n",
       "2  0.789681  0.029041  0.028958  0.020588  0.008913  0.003515  0.003264   \n",
       "3  0.657682  0.054741  0.046521  0.063355  0.061896  0.012435  0.009378   \n",
       "4  0.504094  0.034468  0.042860  0.044064  0.058678  0.057220  0.027059   \n",
       "\n",
       "          7         8         9  ...  246  247  248  249  250  251  252  253  \\\n",
       "0  0.025591  0.018202  0.014061  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.022263  0.020820  0.022773  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.003557  0.003264  0.003348  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.008336  0.007873  0.007341  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.018378  0.015293  0.012732  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        254  label  \n",
       "0  0.000000      0  \n",
       "1  0.000021      0  \n",
       "2  0.000000      0  \n",
       "3  0.000000      0  \n",
       "4  0.000000      0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = dataframe.drop(columns=['Unnamed: 0', 'img_ids'])\n",
    "clean_data = clean_data.replace({\n",
    "    'fresh_apple': 0,\n",
    "    'stale_apple': 1,\n",
    "})\n",
    "clean_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "x = clean_data.iloc[:,:-1]\n",
    "y = clean_data.iloc[:,-1:]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scalled = scaler.fit_transform(x_train)\n",
    "x_test_scalled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \n",
    "         \"RBF SVM\", \n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\", \n",
    "         \"Neural Network\", \n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(max_iter=5000),\n",
    "    GaussianNB(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## MODEL NAME : Nearest Neighbors\n",
      "[[ 86   9]\n",
      " [ 15 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88        95\n",
      "           1       0.92      0.87      0.89       116\n",
      "\n",
      "    accuracy                           0.89       211\n",
      "   macro avg       0.88      0.89      0.89       211\n",
      "weighted avg       0.89      0.89      0.89       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Linear SVM\n",
      "[[ 77  18]\n",
      " [ 10 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        95\n",
      "           1       0.85      0.91      0.88       116\n",
      "\n",
      "    accuracy                           0.87       211\n",
      "   macro avg       0.87      0.86      0.86       211\n",
      "weighted avg       0.87      0.87      0.87       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : RBF SVM\n",
      "[[ 90   5]\n",
      " [ 11 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        95\n",
      "           1       0.95      0.91      0.93       116\n",
      "\n",
      "    accuracy                           0.92       211\n",
      "   macro avg       0.92      0.93      0.92       211\n",
      "weighted avg       0.93      0.92      0.92       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Decision Tree\n",
      "[[ 92   3]\n",
      " [  7 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        95\n",
      "           1       0.97      0.94      0.96       116\n",
      "\n",
      "    accuracy                           0.95       211\n",
      "   macro avg       0.95      0.95      0.95       211\n",
      "weighted avg       0.95      0.95      0.95       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Random Forest\n",
      "[[ 94   1]\n",
      " [  1 115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        95\n",
      "           1       0.99      0.99      0.99       116\n",
      "\n",
      "    accuracy                           0.99       211\n",
      "   macro avg       0.99      0.99      0.99       211\n",
      "weighted avg       0.99      0.99      0.99       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Neural Network\n",
      "[[ 93   2]\n",
      " [  3 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        95\n",
      "           1       0.98      0.97      0.98       116\n",
      "\n",
      "    accuracy                           0.98       211\n",
      "   macro avg       0.98      0.98      0.98       211\n",
      "weighted avg       0.98      0.98      0.98       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Naive Bayes\n",
      "[[ 44  51]\n",
      " [  2 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.46      0.62        95\n",
      "           1       0.69      0.98      0.81       116\n",
      "\n",
      "    accuracy                           0.75       211\n",
      "   macro avg       0.82      0.72      0.72       211\n",
      "weighted avg       0.81      0.75      0.73       211\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in zip(names, classifiers):\n",
    "  model.fit(x_train_scalled, y_train.values.ravel())\n",
    "  y_pred_model = model.predict(x_test_scalled)\n",
    "  print(f'## MODEL NAME : {name}')\n",
    "  print(confusion_matrix(y_test, y_pred_model))\n",
    "  print(classification_report(y_test, y_pred_model))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2', -0.3803849219079016), ('3', -0.3630540302388689), ('1', -0.36120411795860524), ('90', -0.3476533290230483), ('0', -0.3234773092014505), ('69', -0.30974609641011863), ('72', -0.3090792673262374), ('68', -0.3090583653363585), ('80', -0.2995090631730869), ('67', -0.2956565914770542), ('70', -0.2932132703014692), ('79', -0.29181685096749077), ('75', -0.28927610209945054), ('73', -0.2861862681904432), ('77', -0.28172509245488364), ('4', -0.28082415371044567), ('83', -0.28044185221798285), ('78', -0.28007748883866285), ('76', -0.2780501119451788), ('88', -0.27757799576063996), ('74', -0.2753576545530219), ('81', -0.27484667358951687), ('82', -0.2687093822584774), ('89', -0.26376267985138785), ('66', -0.26265132310862443), ('71', -0.25696225761108943), ('87', -0.2551071356622639), ('86', -0.24857605147095302), ('84', -0.2443178655700492), ('65', -0.2399649065554915), ('91', -0.22699549682449482), ('85', -0.22250378137501528), ('120', -0.21435697951202845), ('93', -0.2138789824632109), ('92', -0.21206508942212057), ('96', -0.21038011324342162), ('64', -0.20847666505020196), ('94', -0.20425440789173577), ('95', -0.1937561900280427), ('63', -0.18856647530509144), ('100', -0.187327373759999), ('5', -0.17919144928148287), ('59', -0.17221408361800272), ('97', -0.16604480998568177), ('62', -0.1558316895267352), ('98', -0.1509326489259446), ('105', -0.14469458619699962), ('102', -0.14450085652422204), ('99', -0.13583141553670458), ('101', -0.1264473673881255), ('103', -0.11576414398826115), ('108', -0.11570677128233783), ('110', -0.11357149407680195), ('111', -0.10941124391672867), ('104', -0.10568765638676177), ('112', -0.1029226035385303), ('61', -0.10219962077154698), ('106', -0.1012863665980481), ('134', -0.09964709875964335), ('128', -0.09621173306436959), ('127', -0.09268607779801606), ('109', -0.09142947300111236), ('125', -0.09116075310519337), ('113', -0.08901254293307975), ('6', -0.08892359008427088), ('129', -0.08763806796567483), ('107', -0.08763256340389802), ('139', -0.08691673983378334), ('131', -0.08428653595170625), ('114', -0.08310072309400511), ('145', -0.08075839607728835), ('143', -0.07982668395280533), ('126', -0.07980393948990554), ('124', -0.07554071705090681), ('132', -0.0754808619466484), ('137', -0.07533895311394972), ('130', -0.07490138376556472), ('115', -0.0732167496861892), ('123', -0.07301146758830686), ('121', -0.07279762147756676), ('118', -0.0724100999333855), ('60', -0.07184996171990113), ('141', -0.07104790454139785), ('136', -0.07023137824634179), ('142', -0.07015053237751041), ('119', -0.06980907241672558), ('116', -0.06618621209140241), ('133', -0.06571680884151426), ('147', -0.064834592865437), ('152', -0.0628838026421549), ('138', -0.0602577526620695), ('117', -0.05956512206403018), ('144', -0.059466557448947494), ('135', -0.05932205419355129), ('146', -0.05899972642409561), ('161', -0.05685195011539779), ('156', -0.05591620152106307), ('163', -0.0550950147808687), ('158', -0.05391633674094833), ('151', -0.052893201784616053), ('122', -0.05250011628149439), ('140', -0.051622451724345), ('157', -0.05126762770574519), ('150', -0.05108243631020393), ('168', -0.05104574011834872), ('177', -0.05050999635584517), ('148', -0.050472573966203436), ('160', -0.04973065160480281), ('181', -0.04944035163624624), ('169', -0.048839237151782934), ('176', -0.046735700843416876), ('175', -0.046220977887005917), ('170', -0.045735269786579366), ('165', -0.04541769499522991), ('153', -0.04465660315795352), ('178', -0.039241634200952405), ('154', -0.03525540163771628), ('179', -0.030788521136796785), ('182', -0.02969460680656835), ('171', -0.027237413737226903), ('183', -0.022424552056534555), ('162', -0.016896481508353944), ('173', -0.0069714524429716805), ('186', -0.00478530202915596), ('174', -0.003823112972966412), ('172', -0.0028133149306176163), ('155', 0.002231154309164791), ('166', 0.004885871738638145), ('164', 0.0054717489932314765), ('58', 0.010482799581850489), ('167', 0.013698193993643892), ('56', 0.014943991813360322), ('57', 0.015833523113169594), ('7', 0.017456756114262048), ('149', 0.027164831245557748), ('54', 0.044787456457242567), ('55', 0.048359682739474705), ('8', 0.07961393923813971), ('53', 0.12753344998569102), ('49', 0.14143141945337534), ('50', 0.14327404646773262), ('51', 0.16194396351449908), ('48', 0.16903640890693608), ('52', 0.1751732222687557), ('9', 0.17561212032666287), ('47', 0.19358960253779253), ('45', 0.20828629123045708), ('46', 0.2095174946480334), ('44', 0.22966351320618547), ('10', 0.24656369042175696), ('43', 0.2601885984800915), ('42', 0.2710997821047086), ('40', 0.27952145774055015), ('41', 0.2798812026657024), ('39', 0.28244891100195135), ('38', 0.28541889912876756), ('37', 0.28733792670130115), ('11', 0.32077943988774726), ('36', 0.3399453419412187), ('12', 0.3520423424555388), ('35', 0.3692174390579831), ('34', 0.38184271331569614), ('13', 0.39380844807014), ('33', 0.42562147259907096), ('32', 0.43197983128267253), ('31', 0.4357867327607645), ('14', 0.44081265153754656), ('30', 0.44330792962388543), ('15', 0.452729365183107), ('29', 0.4732567156972049), ('16', 0.4739579550763667), ('28', 0.5002777268750612), ('17', 0.5020390813212856), ('18', 0.5135921597316854), ('27', 0.5292859754056828), ('19', 0.537074835442724), ('26', 0.5474626023425097), ('23', 0.5520907894295269), ('25', 0.5569002048012474), ('20', 0.5640660035737837), ('24', 0.5645775711377922), ('21', 0.5677636788274949), ('22', 0.5770276475018273), ('180', nan), ('202', -0.0012753533906772051), ('217', 0.008408349288121241), ('197', 0.019800638544414852), ('240', 0.023610498788139277), ('213', 0.02920412811497497), ('195', 0.029816418067143413), ('199', 0.03204200655412319), ('238', 0.03204200655412322), ('188', 0.038986950591836586), ('192', 0.042236611902259816), ('184', 0.04546879789829223), ('191', 0.04589871192682409), ('185', 0.04611939956748182), ('189', 0.046302616076117624), ('206', 0.04685974456975123), ('198', 0.04709613484362137), ('190', 0.05038106719260995), ('219', 0.0542482487919887), ('209', 0.05503183338995842), ('211', 0.05596084997836076), ('205', 0.05634037346127367), ('242', 0.05861331031887334), ('215', 0.059148440390126), ('233', 0.06011593956998774), ('214', 0.060544918814783306), ('204', 0.061514507120308155), ('237', 0.06173404597417202), ('226', 0.06400116329679688), ('207', 0.06431942061094317), ('208', 0.06553757833573408), ('212', 0.06698105590581223), ('254', 0.06708095165989537), ('193', 0.0674282022937286), ('232', 0.06763954013345075), ('194', 0.06793933532295732), ('251', 0.06862093404431514), ('227', 0.07026131397182911), ('236', 0.07039734735067174), ('220', 0.07064526574086762), ('187', 0.07106995656890036), ('230', 0.07199655906368728), ('229', 0.07588471267700703), ('159', 0.07640485442626327), ('243', 0.07685924680125363), ('234', 0.07725463196372698), ('210', 0.07776786695372019), ('196', 0.0781916538215484), ('200', 0.0784340047038183), ('222', 0.08066728860354704), ('221', 0.08102926361585899), ('225', 0.08157923365384126), ('223', 0.08186609399648843), ('244', 0.08219000910554611), ('218', 0.08386302352409535), ('250', 0.08524703687091598), ('216', 0.08716854850788176), ('249', 0.08822482153039009), ('228', 0.08867422872267675), ('245', 0.09096571127759522), ('252', 0.09128878536074152), ('201', 0.09140600013812891), ('248', 0.09233156539621941), ('235', 0.09301635689040921), ('224', 0.09538056584183363), ('231', 0.09619328532950047), ('239', nan), ('241', nan), ('246', 0.09791756357026674), ('247', 0.10418916443281741), ('203', 0.10699317355608239), ('253', 0.12608425396266268), ('label', 0.9999999999999999)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = {}\n",
    "label = clean_data['label']\n",
    "for col in clean_data.columns:\n",
    "  correlation[col] = label.corr(clean_data[col])\n",
    "sorted_correlation = sorted(correlation.items(), key=lambda x: x[1])\n",
    "print(sorted_correlation)\n",
    "len(sorted_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_corr = {}\n",
    "negative_corr = {}\n",
    "for (k,v) in sorted_correlation:\n",
    "  if(v>0):\n",
    "    positive_corr[k] = v\n",
    "  else:\n",
    "    negative_corr[k] = v\n",
    "len(positive_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = len(positive_corr))\n",
    "x_train_pca = pca.fit_transform(x_train_scalled)\n",
    "x_test_pca = pca.transform(x_test_scalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## MODEL NAME : Nearest Neighbors\n",
      "[[ 86   9]\n",
      " [ 15 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88        95\n",
      "           1       0.92      0.87      0.89       116\n",
      "\n",
      "    accuracy                           0.89       211\n",
      "   macro avg       0.88      0.89      0.89       211\n",
      "weighted avg       0.89      0.89      0.89       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Linear SVM\n",
      "[[ 77  18]\n",
      " [ 10 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        95\n",
      "           1       0.85      0.91      0.88       116\n",
      "\n",
      "    accuracy                           0.87       211\n",
      "   macro avg       0.87      0.86      0.86       211\n",
      "weighted avg       0.87      0.87      0.87       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : RBF SVM\n",
      "[[ 89   6]\n",
      " [ 11 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        95\n",
      "           1       0.95      0.91      0.93       116\n",
      "\n",
      "    accuracy                           0.92       211\n",
      "   macro avg       0.92      0.92      0.92       211\n",
      "weighted avg       0.92      0.92      0.92       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Decision Tree\n",
      "[[86  9]\n",
      " [18 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.86        95\n",
      "           1       0.92      0.84      0.88       116\n",
      "\n",
      "    accuracy                           0.87       211\n",
      "   macro avg       0.87      0.88      0.87       211\n",
      "weighted avg       0.88      0.87      0.87       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Random Forest\n",
      "[[ 92   3]\n",
      " [  3 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        95\n",
      "           1       0.97      0.97      0.97       116\n",
      "\n",
      "    accuracy                           0.97       211\n",
      "   macro avg       0.97      0.97      0.97       211\n",
      "weighted avg       0.97      0.97      0.97       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Neural Network\n",
      "[[ 92   3]\n",
      " [  2 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        95\n",
      "           1       0.97      0.98      0.98       116\n",
      "\n",
      "    accuracy                           0.98       211\n",
      "   macro avg       0.98      0.98      0.98       211\n",
      "weighted avg       0.98      0.98      0.98       211\n",
      "\n",
      "\n",
      "\n",
      "## MODEL NAME : Naive Bayes\n",
      "[[83 12]\n",
      " [47 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74        95\n",
      "           1       0.85      0.59      0.70       116\n",
      "\n",
      "    accuracy                           0.72       211\n",
      "   macro avg       0.75      0.73      0.72       211\n",
      "weighted avg       0.76      0.72      0.72       211\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in zip(names, classifiers):\n",
    "  model.fit(x_train_pca, y_train.values.ravel())\n",
    "  y_pred_model = model.predict(x_test_pca)\n",
    "  try:\n",
    "    print(f'## MODEL NAME : {name}')\n",
    "    print(confusion_matrix(y_test, y_pred_model))\n",
    "    print(classification_report(y_test, y_pred_model))\n",
    "    print('\\n')\n",
    "  except:\n",
    "    print(\"Hello!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5b361f6ca7fafae1daa726a61efe953255fbf5df0ee7edb2373f2ea1774ef95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
